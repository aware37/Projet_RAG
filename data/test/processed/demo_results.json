[
  {
    "id": 1,
    "question": "Qu'est-ce que la méthode MRD propose ?",
    "baseline_response": "La méthode MRD (Mean Residual Disease) est un outil utilisé en oncologie pour évaluer la réponse à un traitement anticancéreux. Il s'agit de mesurer le taux résiduel de maladie dans les cellules tumorales restantes après une première phase de traitement pour déterminer la réponse au traitement (complete response, partial response, stable disease ou progressive disease) et ainsi guider le choix du traitement suivant.",
    "baseline_time": 28.08,
    "baseline_length": 419,
    "rag_response": "La méthode MRD (Multi-resolution Retrieval-Detection Fusion) propose une méthode de fusion pour l'entendre des images à haute résolution par les réseaux de neurones profonds multi-échelon (MLLMs). Elle utilise deux modules principaux : RAG et OVD. RAG (Retrieval-Augmented Guidance) est utilisé pour obtenir une carte de similitude sémantique, tandis que OVD (Objectness Verification Detection) fournit une carte de confiance de détection d'objets. En intégrant ces deux modules, les objets cibles peuvent être localisés avec plus de précision. En plus, MRD améliore considérablement la compréhension des images à haute résolution pour les MLLMs en ajoutant un processus d'analyse multiresolution et en améliorant la localisation des objets similaires.",
    "rag_time": 200.27,
    "rag_length": 752,
    "rag_sources_count": 5,
    "rag_sources": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5. Experiments | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 1. Introduction | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > Introduction",
    "rag_hybrid_response": "La méthode MRD (Multi-resolution Retrieval Detection) propose un nouveau cadre de formation sans entraînement pour améliorer la compréhension des images à haute résolution par les modèles de langage de plus haute niveau (MLLMs). Cette méthode utilise une approche multiresolution pour la similarité semantique et corrige les cartes de similarité unirésolue, ce qui assure l'intégrité des objets cibles. Elle présente également un modèle OVD (Open-vocabulary) qui identifie les régions des objets à l'aide d'une approche glissante fenêtre. Cette méthode démontre sa supériorité en termes de performance lorsqu'elle est appliquée à plusieurs banques de données à haute résolution avec différents MLLMs, montrant ainsi un gain significatif dans la compréhension des images à haute résolution.",
    "rag_hybrid_time": 147.42,
    "rag_hybrid_length": 789,
    "rag_hybrid_sources_count": 5,
    "rag_hybrid_sources": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 6. Conclusion | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 3. Preliminary | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.1. Main Results | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.1. Main Results | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 4. Method",
    "rerank_response": "Le MRD (Multiscale Resolution Design) est une méthode qui propose de développer un modèle de compréhension de grande résolution d'images pour les machines à apprendre (MLLMs). Il permet de localiser plus précisément des objets individuels dans des images, mais peut également manquer d'objects dans des scénarios multi-objets. La méthode de fusion de la signification à plusieurs échelles correcte les scores de similarité sémantique et préserve l'intégrité des objets sous différentes conditions, améliorant ainsi le rendement du MLLM pour les tâches mono-objet et multi-objet. Le modèle final intègre tous les modules et obtient une précision plus élevée de 5,7 % par rapport à RAP, démontrant l'efficacité du design de MRD dans l'amélioration de la compréhension des images à haute résolution pour les MLLMs.\nPour mieux comprendre les contributions individuelles des différents modules dans le *MRD* framework, des études d'ablation sont conduites. La table 2 présente un aperçu de ces études.",
    "rerank_time": 159.91,
    "rerank_length": 996,
    "rerank_sources_count": 3,
    "rerank_sources": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5. Experiments"
  },
  {
    "id": 2,
    "question": "Quels sont les résultats expérimentaux principaux ?",
    "baseline_response": "Les résultats expérimentaux principaux dépendent du contexte de l'expérience en question. Il est donc impossible de fournir des réponses précises sans connaître le sujet particulier de la recherche. Cependant, en général, les résultats expérimentaux peuvent inclure des observations, des données statistiques, des tendances ou des prédictions basées sur des recherches ou des tests. Ils peuvent également s'étendre à des découvertes nouvelles, l'annonce de nouveaux produits, la validation ou la réfutation d'hypothèses et l'avancement du savoir dans un domaine donné.",
    "baseline_time": 39.7,
    "baseline_length": 568,
    "rag_response": "Les résultats expérimentaux principaux du travail \"Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding\" indiquent que MRD (MRD) sensiblement améliore les capacités de perception et d'intellection des réseaux de neurones profonds multi-couches (MLLMs) lorsqu'ils sont utilisés pour traiter des images à haute résolution. Ces résultats sont mentionnés dans la source suivante : [Source: MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.1. Main Results].",
    "rag_time": 175.34,
    "rag_length": 527,
    "rag_sources_count": 5,
    "rag_sources": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 3. Preliminary | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5. Experiments | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > Introduction | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.1. Main Results",
    "rag_hybrid_response": "Les résultats expérimentaux principaux indiquent que la méthode proposée, Multi-resolution Retrieval-Detection (MRD), améliore significativement la compréhension des images à haute résolution par les MLLMs. L'introduction de l'OVD modèle aide à localiser plus précisément des objets individuels, mais peut entraîner des objets perdus dans des scénarios multi-objet. La fusion semantique multi-résolution corrige les scores de similitude semantique et maintient l'intégrité des objets sous différentes conditions, améliorant ainsi la performance des MLLMs sur les tâches simples et complexes.\n\nL'étude d'abolition montre que :\n- RAP : 80.0 dans la mesure de l'attribut du benchmark V*, 84.2 dans la mesure spatiale, et 83.6 dans la mesure globale\n- OVD : 84.3 dans la mesure de l'attribut du benchmark V*, 81.6 dans la mesure spatiale, et 84.9 dans la mesure globale\n- RAP+Multi-res : 82.9 dans la mesure de l'attribut du benchmark V*, 85.2 dans la mesure spatiale, et 85.8 dans la mesure globale\n- RAP+OVD : 85.2 dans la mesure de l'attribut du benchmark V*, 84.2 dans la mesure spatiale, et 86.2 dans la mesure globale\n- RAP+OVD+Multi-Res : 90.4 dans la mesure de l'attribut du benchmark V*, 85.5 dans la mesure spatiale, et 89.3 dans la mesure globale\n\nEn utilisant le modèle LLaVA-ov-0.5B sur les données V*, la combinaison de RAP+OVD+Multi-Res améliore significativement l'accuracy de 5.7%, démontrant ainsi l'efficacité du design de MRD dans l'amélioration de la compréhension des images à haute résolution pour les MLLMs.",
    "rag_hybrid_time": 258.45,
    "rag_hybrid_length": 1527,
    "rag_hybrid_sources_count": 5,
    "rag_hybrid_sources": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 6. Conclusion | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study",
    "rerank_response": "Les résultats expérimentaux principaux indiquent que l'introduction de la technologie MRD (Multi-Resolution Depth) améliore considérablement la capacité de perception et de compréhension des modèles de langage multimodal (MLLMs) lorsqu'ils travaillent sur des images à haute résolution. Les tableaux ci-dessus comparent les scores d'adhésion, de précision, de récall et de F1 pour plusieurs models, dont LLaVA-HR-X-13B, LLaVA-HR-X-7B, InternVl-1.5-26B et Yi-VL-34B. Ils montrent que le modèle final qui intègre toutes les modules atteint une acccuracy supérieure de 5.7% à RAP, ce qui démontre l'efficacité de la conception de MRD dans l'amélioration de l'entendement des images à haute résolution pour les MLLMs.",
    "rerank_time": 130.08,
    "rerank_length": 713,
    "rerank_sources_count": 3,
    "rerank_sources": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.1. Main Results | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5. Experiments | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study"
  },
  {
    "id": 3,
    "question": "Quelle est la différence avec les méthodes existantes ?",
    "baseline_response": "Il est difficile de répondre de manière concise sans avoir connaissance précise des méthodes existantes que vous voulez comparer. En général, la principale différence des nouveaux développements dans le domaine du machine learning peut être l'utilisation de nouvelles techniques pour améliorer les résultats, réduire le temps d'exécution ou simplifier la configuration et l'entraînement des modèles. Par exemple, il y a eu un grand progrès dans l'utilisation de l'apprentissage profond (deep learning) et de l'intelligence artificielle (AI) pour résoudre des problèmes plus complexes. D'autres nouveaux développements incluent l'apprentissage sans étiquetage (unsupervised learning), l'apprentissage à partir de données imbalancées et l'utilisation d'architectures neurales différentes comme les réseaux neuronaux auto-encodants ou les réseaux neuronaux convolutifs déconvolutifs.",
    "baseline_time": 63.69,
    "baseline_length": 880,
    "rag_response": "La méthode MRD (Multi-resolution Retrieval-Detection Fusion) présente une amélioration par rapport aux méthodes existantes en termes de compréhension des images à haute résolution pour les réseaux de machines apprenants multi-scales (MLLMs). Selon l'article, la méthode MRD améliore la localisation précise d'objets individuels mais peut entraîner des objets manqués dans les scénarios à plusieurs objets. De plus, le fusionnement multi-résolutionnel de la sémanique corrige les scores de similarité semantique et conserve l'intégrité des objets sous différentes conditions, ce qui améliore les performances du MLLM sur les tâches uni-objet et multi-objet. Le modèle final intègre tous les modules et atteint une précision supérieure de 5,7% au RAP (Récupération Multi-résolutionnelle Approximative), démontrant ainsi l'efficacité de la conception MRD dans l'amélioration de l'entente des images à haute résolution pour les MLLMs.",
    "rag_time": 246.48,
    "rag_length": 930,
    "rag_sources_count": 5,
    "rag_sources": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5. Experiments | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > Introduction | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 3. Preliminary | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5. Experiments",
    "rag_hybrid_response": "La methode MRD proposee dans ce travail est une nouvelle methode entraînement libre (training-free) qui permet d'ameliorer la comprehension des images à haute resolution par les MLMs (Modèles de Langage de Haut Niveau). Les autres methodes existantes peuvent peut-être ne pas utiliser ce principe de fusion multi-résolution entre similarité semantique et detection, ou n'utiliser qu'une seule approche sans integration des autres. La particularite de MRD est de combiner plusieurs strategies pour ameliorer la precision dans l'identification et la comprehension des objets dans les images à haute resolution, ce qui fait de cette methode plus efficace selon les auteurs.",
    "rag_hybrid_time": 156.11,
    "rag_hybrid_length": 670,
    "rag_hybrid_sources_count": 5,
    "rag_hybrid_sources": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 6. Conclusion | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study",
    "rerank_response": "La table montre des résultats de différents modèles de traitement d'images. Les modèles sont basés sur un type de réseau neuronal appelé LLaVA (Large Language-guided Vision and Actions). Il y a plusieurs versions de ces modèles, telles que LLaVA-HR, LLaVA-ov, et LLaVA-v1.5, ainsi qu'une version améliorée appelée MRD (Mixed Recurrence Decoder).\n\nLes colonnes de la table représentent différents indicateurs de performance pour chaque modèle sur diverses tâches d'apprentissage automatique telles que la classification et la détection d'objets. Les indicateurs de performance varient entre 33.0 % (pire résultat) et 97.4 % (meilleur résultat).\n\nLes modèles MRD (Mixed Recurrence Decoder) ont généralement des performances supérieures aux autres versions, ce qui suggère qu'une version améliorée du réseau neuronal LLaVA a été conçue pour obtenir des résultats plus performants.\n\nEn comparaison avec les méthodes existantes, il n'est pas spécifié précisément dans le tableau ce qui est considéré comme \"les méthodes existantes\". Cependant, ces modèles LLaVA appartiennent à la catégorie des réseaux neuronaux de style transformer pré-entraînés sur une base très large de données. Ils sont conçus pour être capables d'effectuer plusieurs tâches d'apprentissage automatique telles que la classification et la détection d'objets en utilisant des descriptions textuelles ou des captions associées aux images comme entrée. Les méthodes existantes peuvent donc inclure les modèles de traitement d'images tels que ResNet, VGG, Inception, etc., qui sont basés sur des architectures différentes et utilisent généralement des techniques telles que la convolution en profondeur pour effectuer ces tâches. Les LLaVA semblent améliorer les performances de ces autres modèles en utilisant un approche différente, notamment en intégrant une capacité à comprendre et interpréter des descriptions textuelles associées aux images.",
    "rerank_time": 310.82,
    "rerank_length": 1911,
    "rerank_sources_count": 3,
    "rerank_sources": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5. Experiments | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5. Experiments | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5. Experiments"
  },
  {
    "id": 4,
    "question": "Quels datasets sont utilisés pour l'évaluation ?",
    "baseline_response": "Les datasets utilisés pour l'évaluation varient en fonction du contexte. Dans le domaine des modèles de langage naturel, les datasets communs comprennent GLUE, SuperGLUE, Stanford NLP, Ubuntu Dialog Corpus (UDC) et Common Crawled Corpus (CCC). Cependant, pour une évaluation spécifique, il est recommandé de vérifier le guide de référence ou de consulter la documentation du projet.",
    "baseline_time": 30.62,
    "baseline_length": 382,
    "rag_response": "Les datasets utilisés pour l'évaluation sont ceux du V* dataset, comme mentionné dans la partie 5.4 de l'article \"Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding\".",
    "rag_time": 126.3,
    "rag_length": 199,
    "rag_sources_count": 5,
    "rag_sources": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > Introduction | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 3. Preliminary | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 4.2. Open-vocabulary Detector Enhancement | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 1. Introduction",
    "rag_hybrid_response": "Les datasets utilisés pour l'évaluation sont V*, HR-Bench 4K, et HR-Bench 8K, comme mentionné dans la description de tableau 1.",
    "rag_hybrid_time": 140.58,
    "rag_hybrid_length": 127,
    "rag_hybrid_sources_count": 5,
    "rag_hybrid_sources": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.1. Main Results | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 4.2. Open-vocabulary Detector Enhancement | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study",
    "rerank_response": "Les données utilisées pour l'évaluation n'apparaissent pas explicitement mentionnées dans le texte fourni. Cependant, il est dit que les résultats ont été obtenus sur le V* dataset en utilisant le LLaVA-ov-0.5B model. Il est possible que d'autres données aient également été utilisées pour comparer VisRAG avec les autres modèles, mais cela n'est pas clairement spécifié dans le texte fourni.",
    "rerank_time": 86.32,
    "rerank_length": 392,
    "rerank_sources_count": 3,
    "rerank_sources": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 4.2. Open-vocabulary Detector Enhancement | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5. Experiments"
  },
  {
    "id": 5,
    "question": "Quelles sont les limitations de l'approche ?",
    "baseline_response": "L'approche peut être limitée par des facteurs tels que :\n1. Simplicité : Les modèles peuvent présenter une simplicité excessive, ignorant certaines complexités réelles du monde.\n2. Validité : La validité des résultats dépend de l'exactitude avec laquelle le monde est représenté et des paramètres utilisés.\n3. Transfert : Les modèles peuvent ne pas représenter les relations entre les variables correctement, ce qui peut entraîner un transfert invalide vers des situations réelles différentes.\n4. Interprétation : Les résultats d'un modèle peuvent être difficiles à interpréter et peuvent nécessiter des compétences techniques avancées pour être utilisés efficacement.\n5. Coût : Le coût de la conception, de l'exécution et de l'entretien d'un modèle peut être élevé, particulièrement pour les modèles plus complexes.",
    "baseline_time": 58.78,
    "baseline_length": 816,
    "rag_response": "En utilisant le contexte fourni, l'article présente l'approche MRD pour améliorer la compréhension et la perception des images à haute résolution par les MLLMs (Modèles de Langage de Haut Niveau).\n\nSelon l'ablation étudiée, il est mentionné que l'introduction du OVD (One-Vote Detection) aide à localiser plus précisément des objets individuels, mais peut entraîner la perte d'objets dans des scénarios multi-objet. De plus, lors de la fusion des scores de similarité semantique multiresolution, il est possible que les parties différentes d'un objet ne soient pas complètement intégrées, ce qui peut entraîner une perte de précision dans la compréhension de l'image à haute résolution.\n\nAinsi, les limitations potentielles de l'approche MRD pourraient être :\n\n1. La présence d'objets perdus lors de situations multi-objet avec l'introduction du One-Vote Detection (OVD).\n2. Une perte de précision dans la compréhension de l'image à haute résolution due à une fusion incomplète des parties différentes d'un objet.",
    "rag_time": 168.09,
    "rag_length": 1013,
    "rag_sources_count": 5,
    "rag_sources": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.1. Main Results | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 3. Preliminary | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 3. Preliminary | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 4. Method",
    "rag_hybrid_response": "L'approche proposée, Multi-resolution Retrieval-Detection (MRD), est efficace pour améliorer la compréhension des images à haute résolution par les MLLMs. Cependant, il y a quelques limitations à noter :\n\n1. Localisation de plusieurs objets : L'introduction de l'OVD pour localiser les objets individuels est efficace mais peut entraîner des objets manquants dans des scénarios multi-objet.\n2. Résultats dégradés sur certaines tâches multi-objet : Lorsque la similarité semantique cartographiée est fusionnée avec la carte de confiance de détection de l'OVD, les performances sont améliorées sur des tâches à un objet, mais les résultats sont même pires que l'utilisation de l'OVD seule dans des scénarios multi-objet, ce qui suggère qu'un certain nombre d'objets cibles peuvent être perdus lors de la recherche.\n3. Limite à certains modèles MLLM : Les performances de MRD ont été démontrées en utilisant différents MLLMs, mais il est important de noter que les résultats peuvent varier avec des modèles MLLM différents et que l'optimisation pour d'autres MLLM spécifiques peut être nécessaire.\n4. Taux de calcul élevé : Les approches multi-résolution peuvent entraîner un taux de calcul plus élevé, ce qui peut entrainer des temps d'exécution plus longs et une consommation plus importante de ressources computationnelles.\n5. Limitation à l'amélioration de la compréhension de l'image : MRD a été conçu pour améliorer la compréhension de l'image par les MLLMs, mais sa capacité à améliorer d'autres aspects tels que la ségrégation ou la segmentation précise des objets est inconnue et nécessite de futures recherches.\n\nEn résumé, bien que MRD soit efficace pour améliorer la compréhension des images à haute résolution par les MLLMs, il y a encore des possibilités d'amélioration en termes de localisation de plusieurs objets, coûts computationnels, et capacité à améliorer d'autres aspects tels que la ségrégation ou la segmentation précise des objets.",
    "rag_hybrid_time": 273.26,
    "rag_hybrid_length": 1954,
    "rag_hybrid_sources_count": 5,
    "rag_hybrid_sources": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 6. Conclusion | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 5.4. Ablation Study",
    "rerank_response": "Les limiteurs de l'approche sont les suivants :\n\n1. La méthode de patching peut fragmenter des objets importants en plusieurs parties distinctes, ce qui perturbe leurs semantiques holistiques et provoque des calculs de similarité biaisés. Certaines patches peuvent ainsi obtenir des scores de similarité anormaux malgré leur irrelevance à la requête.\n2. Le paramètre de résolution de patch est crucial mais difficile à régler : une taille de patch trop grande présente de l'informations de fond superflue, tandis qu'une taille trop petite accroît le fragmentation des objets. Les expériences ont montré que la choix de résolution a un impact significatif sur les performances.\n3. Dans les images à haute résolution avec des fonds clutrés, la mesure de similarité est sujette aux fausses positives où des régions de fond peuvent obtenir une similitude plus élevée que celles contenant les objets cibles réels, ce qui entrave la reconnaissance.\n4. Il est également difficile pour les modèles de percevoir en détail les images à haute résolution, ce qui constitue un enjeu important dans la recherche émergente sur l'amélioration de la capacité de perception d'images à haute résolution des MLLMs. Pour améliorer cela, une stratégie courante consiste à localiser et à zoomer. Bien que les approches de formation telles que le Supervised Fine-Tuning (SFT) et la Fusion par Réinforcement soient utilisées pour améliorer la détection des objets, il est toujours nécessaire d'améliorer la compréhension globale de l'image.",
    "rerank_time": 158.35,
    "rerank_length": 1515,
    "rerank_sources_count": 3,
    "rerank_sources": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 1. Introduction | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 1. Introduction | MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding > 4. Method"
  }
]